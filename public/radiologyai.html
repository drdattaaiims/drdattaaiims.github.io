<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Should You Choose Radiology in 2025? A No Bull$hit Guide</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Honest, evidence-based guidance for medical students choosing radiology in the AI era—what will change, what won't, and how to build a future-proof career.">
  
  <link rel="stylesheet" href="/assets/index-B9idXD11.css">

  <!-- Google Font -->
  <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  
  <style>
    :root {
      --bg: linear-gradient(135deg, #f8fafc, #eef2ff, #e0f2fe);
      --text: #111827;
      --muted: #475569;
      --accent: #0b5ed7; /* darker premium blue */
      --border: #e5e7eb;
      --table: #f9fafb;
    }
  
    html, body {
      margin: 0;
      padding: 0;
      background: var(--bg);
      color: var(--text);
      font: 18px/1.7 "Raleway", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    }
  
    main {
      max-width: 820px;
      margin: 60px auto;
      padding: 50px 40px;
      background: rgba(255, 255, 255, 0.92);
      border-radius: 24px;
      box-shadow: 0 4px 40px rgba(0, 0, 0, 0.05);
    }
  
    header h1 {
      font-size: 2.4rem;
      line-height: 1.2;
      margin: 0 0 12px;
      font-weight: 700;
      color: var(--accent);
    }
  
    header p.byline {
      color: var(--muted);
      margin: 0 0 32px;
      font-size: 1.05rem;
      line-height: 1.6;
      font-style: italic;
    }
  
    article h2 {
      margin-top: 48px;
      font-size: 1.6rem;
      line-height: 1.3;
      font-weight: 600;
    }
  
    article h3 {
      margin-top: 32px;
      font-size: 1.25rem;
      font-weight: 600;
    }
  
    article p {
      margin: 16px 0;
      text-align: justify;
    }
  
    a {
      color: var(--accent);
      text-decoration: none;
    }
  
    a:hover {
      text-decoration: underline;
    }
  
    blockquote {
      margin: 24px 0;
      padding: 16px 20px;
      border-left: 4px solid var(--accent);
      background: #f0f9ff;
      font-style: italic;
    }
  
    .callout {
      background: #f8fafc;
      border: 1px solid var(--border);
      padding: 20px 24px;
      border-radius: 12px;
      margin: 24px 0;
    }
  
    table {
      width: 100%;
      border-collapse: collapse;
      background: var(--table);
    }
  
    th, td {
      padding: 12px 16px;
      border-bottom: 1px solid var(--border);
      text-align: left;
      vertical-align: top;
    }
  
    th {
      font-weight: 600;
      background: #f9fafb;
    }
  
    hr {
      border: none;
      border-top: 1px solid var(--border);
      margin: 40px 0;
    }
  
    footer {
      margin-top: 48px;
      padding-top: 20px;
      border-top: 1px solid var(--border);
      color: var(--muted);
      font-size: 0.95rem;
    }
  </style>
</head>
<body>
<main>
  <header>
    <h1>Should You Choose Radiology in 2025? A No Bull$hit Guide</h1>
    <p class="byline">By Suvrankar Datta, a radiologist and AI researcher, trained at AIIMS New Delhi and currently leading the Centre for Responsible Autonomous Systems in Healthcare (CRASH Lab) at Ashoka University's Koita Centre for Digital Health. If you're worried about AI in radiology right now, here's the only blog you need to read.</p>
  </header>

  <article>
    <h2 id="intro">Why This Blog Matters (More Than You Think)</h2>
    <p>If you're reading this, you're probably lying awake wondering if radiology is a safe bet anymore. I get it. I was in the same place some time back, except I was convinced AI would eat my career before I finished residency.</p>
    <p>I read the breathless headlines about deep learning crushing board-certified radiologists on test datasets. I also watched Geoffrey Hinton tell a room full of people to stop training radiologists because neural networks would do it better and cheaper. It was precisely around the same time that my AI journey started (around 2017) and I started spending a lot more time in IIT Madras than the JIPMER campus (thank you to my friends for the proxies), where I was doing my MBBS.</p>
    
    <p>Eight years later, I'm still here. And so is every radiologist I trained with. And honestly, they're busier than ever.</p>
    <p>Geoffrey is a smart person (I mean he won the Nobel Prize), but he was not a radiologist. There are a lot of things which AI will replace before it comes for radiologists, he could have taken a safer bet.</p>
    
    <p>So, here's the thing! Today, doomers screaming "radiology is dead!" and optimists saying "AI will never replace doctors!" are both wrong. I like to have fun on X and have often taken both sides, depending on which phase of the Gartner Hype Cycle for Radiology AI I am traversing. The reality though is very complicated, more interesting and way more dependent on <em>law and policy</em> than anyone on X has an experience in or wants to admit. I am no expert but being in student and RDA unions throughout my life and continuing to be in policy roundtables even today, I have seen how policy and laws get created and how difficult it is for domain experts (or even economists, who are helping run the country) to predict. </p>
    
    <p>After spending nearly a decade building AI systems, validating AI in real hospitals and watching many of them fail to deploy or perform as they had promised, I've learned my biter lesson - that building the technology is only half the story. It is probably much easier today to devlop an AI model than deploy that at scale (before AI developers get offended, I am comparing with the tech we had in 2017 when I started). A lot of AI implementation depends on regulation, liability, workforce shortages and human factors that no human being can predict with a 100% guarantee.</p>
    
    <p>This no bull$shit guide is my attempt to cut through the noise and give you a semi-evidence-based picture. If I wrote a paper, none of you would read! But this blog has what I believe is all you need to know as you decide your residency in 2025. I cannot answer questions like "Will Radiologists be replaced?" or "Should I take radiology?" as I do not think anyone knows or should answer to this today.</p>

    <div class="callout">
      <strong>TL;DR (in case you do not want to read through the entire article)</strong>
      <p>Here's the reality in short: AI today is getting better at narrow pattern-recognition tasks and even generalist tasks, and it will keep improving fast. But replacing doctors isn't blocked by <em>accuracy</em> anymore. It's blocked by <em>law and liability</em>.</p>
      <p>Regulation is tightening everywhere. The EU AI Act classifies most clinical AI as high-risk, requiring explicit human oversight.<sup>1,2</sup> The FDA's approval list is long but every device assumes a human in the loop.<sup>3</sup> In India, the Digital Personal Data Protection Act and medical device rules are not going to make AI development or deployment easy.<sup>9,11</sup></p>
      <p>And here's the kicker: because radiologists are scarce, the UK just spent £216 million outsourcing reads in a single year<sup>6</sup>-policy bends toward safe <em>augmentation</em>, not autonomy. Yet.</p> 
      <p>A flood of mediocre models is coming, which means stricter post-market monitoring and recalls as real-world errors surface. You'll become dependent on these tools, but with discipline and oversight. Your career strategy? Lean into interventional radiology, preventive imaging programs, clinic leadership, and AI governance literacy. Those are your moats.</p>
    </div>

    <h2 id="what-ai-does">What AI Actually Does Today (vs. What X Claims)</h2>
    <p>Let's start with what works <em>today</em>, not in some speculative future. AI tools in radiology right now majorly help with triage (flagging urgent cases), quality control (catching technical errors), measurements (tumor volumes, bone density) and report drafting.</p>
    <p>A big cross-European survey of radiologists found these are the functions doctors actually trust and use in daily practice.<sup>4</sup> Notice the pattern? All of these need <em>you</em> to still read the scan and sign the report.</p>
    
    <p>So why isn't there "replacement"? Three reasons, and they're all about systems, not just technology. And that is why Geoffrey made a miscalculation.</p>
    
    <p><strong>First, we have regulations.</strong> The FDA has cleared over 900 AI devices (as per latest literature bit I think it is over 1000 now) for medical use,<sup>3</sup> and yes, that number sounds scary. But if you actually read the approval letters, they're for <em>narrow, specific intended uses</em> with explicit disclaimers that a qualified physician must review the output. These aren't autonomous diagnostic systems. They're assistants that generate suggestions, and you're liable for what gets reported. The legal framework treats them more like a second opinion tool (researchers please do not catch me on this term - this blog is meant for medical students and residents) than a replacement of radiologists.</p>
    
    <p><strong>Second, current risk classification of AI tools.</strong> Under the EU AI Act (already influencing India's policy), most (not all) clinical and diagnostic AI falls into the "high-risk" category.<sup>1,2</sup> That means mandatory risk management systems, high-quality training data with known biases documented, transparent user information, and most critically, <em>explicit human oversight</em> baked into the design. AI governance work is becoming clinical work. If you're annoyed by paperwork now, wait until you're the designated model steward for your department. You will want an AI for that work desperately lol.</p>
    
    <p><strong>Third, there are human factors.</strong> Even when AI is accurate, humans mess up the interaction. The literature is full of studies showing <em>automation bias</em> where experienced readers getting nudged by wrong AI suggestions and missing things they'd normally catch.<sup>12,13,14</sup> Radiologists in one mammography study were more likely to overlook subtle cancers when an AI wrongly flagged a different area as suspicious.<sup>12</sup> Another study on cerebral aneurysm detection found that wrong AI suggestions actively degraded reader performance.<sup>13</sup> This isn't theoretical; it's happening in pilot studies right now. The answer isn't to throw AI out, but to design guardrails: deliberate training, cross-checks and incident reporting systems that actually work.</p>

    <h2 id="shortage">Why Governments Move Slower Than What AI Startups Want</h2>
    <p>Here's something Silicon Valley and Bangalore healthcre AI startups don't want to hear: laws change when <em>shortages</em> bite, not when algorithms get better. And the evidence backs this up everywhere you look.</p>
    
    <p>The Royal College of Radiologists released their 2024 UK workforce census, and the picture is stark! The demand for imaging is outpacing radiologist supply by a wide margin.<sup>5</sup> The NHS is stretched so thin that in 2024 alone, they spent a record £216 million outsourcing radiology reads to private firms and teleradiology companies.<sup>6</sup> Backlogs are measured in months for non-urgent scans. Politicians know this. Hospital administrators know this. This gradually shapes <em>policy</em> more than any AI benchmark.</p>
    
    <p>Also when governments face scarcity, they don't jump straight to "replace doctors with algorithms." They bend toward safe augmentation tools that help existing radiologists work faster and catch more, but still require a licensed professional to sign off. Why? Because when something goes wrong, someone needs to be legally accountable and right now, algorithms can't be sued.<sup>20</sup></p>
    
    <p>In India, AI development and deployment will be shaped by two big frameworks. First, the Digital Personal Data Protection Act (DPDP), which gives patients consent rights over how their health data is used, including by AI systems.<sup>9</sup> Second, the Central Drugs Standard Control Organization (CDSCO) classifies AI software as a medical device under the Medical Devices Rules 2017, which means it needs approval, post-market surveillance and traceable use.<sup>11</sup> The practical result? You won't see "AI-only" reports in Indian hospitals anytime soon, unless you attend my workshops or seminars where I have show the example from the only hospital in India who are doing this (And believe me the clinical residents are REALLY pissed at the False Negatives). There will always be a radiologist's name and signature on that report for the foreseebale future, with audit trails showing how the AI contributed.</p>

    <h2 id="flood">The Coming Wave of Mediocre Models (and How They'll Be Regulated)</h2>
    <p>Here's an uncomfortable truth: model-making has been democratized, but deployment and evaluations haven't picked up. Anyone with a GPU for a few weeks can train or fine tune a model and claim it "detects pneumonia." There are startups launching AI radiology tools every single week. Most of them are very very mediocre.</p>
    
    <p>Why? Because these models fall apart when they see data from a different scanner, a different patient population, or even a different hospital's imaging protocols. We call this "out-of-distribution" failure, and it's a massive problem that most companies don't advertise until after they've signed contracts. A really big AI company exited India after failing miserably at one of India's top hospitals for triaging CT scans.</p>
    
    <p>Regulators know this, which is why frameworks are getting stricter, not looser. The FDA's Predetermined Change Control Plan (PCCP) allows AI companies to update their models but only within a pre-approved envelope of changes, and they have to prove the updates don't break safety or effectiveness.<sup>3</sup> The World Health Organization's guidance on large multimodal models is even more explicit: it calls for <em>local validation</em> on your specific patient population and equipment before you trust any model with clinical decisions, plus ongoing monitoring for drift.<sup>8</sup> If a model starts quietly degrading because your patient mix changed or your CT scanner got a software update, you need to catch it.</p>
    
    <p>For you as a resident: expect more work, not less. Someone in your department will need to be the AI steward—tracking performance metrics, running quarterly validation checks, helping set thresholds (I did it during my Senior Residency), documenting when the AI influenced a decision and knowing when to pull Skynet's plug if things go wrong. That someone might be you.</p>

    <h2 id="dependence">You'll Become Dependent on AI (and That's Okay, If You're Smart About It)</h2>
    <p>If I am honest, calculator-style reliance is inevitable. Once you get used to AI triaging your worklist and pre-measuring nodules, working without it feels like going back to film.</p>
    <p>The literature already flags this as <em>automation bias/neglect</em> and hints at de-skilling when assistive tools are suddenly withdrawn. One of my illustarted co-authors and a very renowned physician scientist Eric Topol wrote about this just last week.<sup>12,13,14</sup> Residents trained with AI available struggle more when they don't have access to it, similar to how GPS dependence has changed how we navigate. We are in fact doing a study on this at the lab and I invite medical students and residents to write to me if you want to be a part of it.</p>
    
    <p>The answer isn't complete abstinence though, it's <em>structured supervision</em> and education. You need to train with AI, but also train <em>without</em> it periodically, so you maintain your baseline skills. Think of it like a pilot practicing manual landings even though autopilot exists. You want to be the person who knows when the AI is wrong, not the person who blindly trusts it.</p>
    
    <p>And here's something else to consider: patients are ambivalent about this stuff. Surveys show mixed trust in AI for medical care, with a strong preference for human doctors in emotionally loaded situations like breaking bad news, discussing end-of-life care, or explaining complex diagnoses.<sup>17,18</sup> A 2025 UK report found that consumers are increasingly frustrated with low-quality chatbots and automated customer service (if you have ever had a bad experience with Zomato or Swiggy, you know what I mean), and that frustration bleeds into healthcare expectations.<sup>19</sup> If we ship "AI slop" (I call it "AI Cringe") aka fast, cheap and inaccurate automation, there will be backlash. Patients will demand their human radiologist back, and rightly so.</p>
    
    <p><strong>Clinic guardrails that are must if you are a radiologist who wants to deploy AI:</strong> Run local validation on your hospital's imaging equipment and patient demographics. Appoint a named model steward who owns the performance monitoring. Document in the radiology report when AI contributed to a finding or changed your interpretation. Monitor for drift i.e. performance decay over time as patient populations or equipment change. Have an incident response plan for when the AI gets something badly wrong. Write plain language patient notes explaining when AI was used in their care. These align with WHO guidance and EU AI Act expectations,<sup>1,8</sup> and more importantly, they build trust.</p>

    <h2 id="human-touch">Where Humans Still Dominate (and Where Radiology Actually Grows)</h2>
    <p>Let's talk about the safe zones; the parts of medicine where AI isn't close to replacing us, and won't be for a reasonably long time.</p>
    
    <p><strong>Surgical and patient-facing specialties</strong> rely on trust and hands-on skill. AI can assist, but it won't replace the judgment call in the OR when something unexpected happens, or the conversation in clinic when a patient needs to understand their treatment options. Patient experience studies repeatedly show that people prefer talking to actual staff over bots when the stakes are high or the interaction is emotionally charged.<sup>17</sup> This isn't sentimentality but psychology and ethics. Medicine is built on relationships, and those relationships still matter.</p>
    
    <p><strong>Interventional Radiology (IR) is your best hedge.</strong> I literally wrote a chapter in some Springer textbook on AI in Interventional Radiology. It was so early that I did not even feel like sharing it with anyone lol. AI in IR helps with targeting lesions, choosing devices and intra-procedural navigation. There are systems that use real-time imaging fusion and robotics to guide catheters more precisely.<sup>15,16</sup> But the workflow remains human led. You're adapting on the fly based on what you see, what the patient tolerates, and what the anatomy allows. Recent reviews forecast higher throughput and safety with AI-assisted guidance, but not fully autonomous IR.<sup>15,16</sup> Why? Because liability, patient variability and the need for real-time judgment aren't going away. If you want a future-proof radiology career, get IR training. It's procedural, it's patient-facing and it's hard to automate.</p>
    
    <p><strong>Preventive radiology</strong> is another growth area. Screening programs for breast and lung cancer, osteoporosis follow-up, incidental findings management, fatty liver detection; they will require a radiologist to oversee the pathway and make the call on borderline cases.<sup>4</sup> There are schools of thought citing this as clinical leadership work, not just image interpretation, where you're designing the screening protocol, deciding on recall thresholds, managing patient anxiety, and integrating imaging into long-term care plans. AI can help, but it can't own the relationship with the patient. But the real reason it is a great area is because there is very less data today to automate this and create generalisable models. There are some ring companies getting into wellness and starting to do these scans but they are far away from generating evidence that it makes any sense.</p>

    <h2 id="economics">Let's Talk About Money (Because I Know You're Thinking About It)</h2>
    <p>Nobody wants to say it out loud, but earning potential matters when you're choosing a specialty, especially if you are thinking about radiology. So let's address it directly.</p>
    
    <p><strong>If you end up in an independent or teleradiology practice,</strong> AI can improve your margins but only if you reinvest the efficiency gains into quality and retention. Faster turnaround times, fewer repeat scans and better structured reports; all of this builds referrer loyalty.</p>
    <p>But if you just pocket the savings and don't reinvest in your radiologists, you'll bleed talent. The UK's cautionary tale is instructive: they starved their radiology workforce for years, and now they're hemorrhaging money on outsourcing.<sup>6</sup> Don't let that happen to your practice.</p>
    
    <p><strong>If you're an employed radiologist,</strong> the invisible work matters. AI doesn't just speed you up but it adds new tasks. Local validation, exception handling, patient callbacks when AI flags something ambiguous, teaching residents how to use the tools safely; all of this takes time, and most contracts don't account for it.</p>
    <p>The American Journal of Roentgenology's Expert Panel on workforce issues explicitly calls for new staffing and reimbursement models that recognize these safety tasks.<sup>7</sup> When you're negotiating your contract, make sure AI stewardship is part of your job description and not free labor.</p>
    
    <p>The other economic reality: if radiologists refuse to adopt safe, auditable AI tools, <em>referring clinicians will</em>. Emergency physicians, oncologists, and surgeons are already experimenting with point-of-care ultrasound AI and direct-to-consumer imaging apps. If we don't set the standards for how AI is used in imaging, someone else will and they'll optimize for speed and cost, not quality and safety, totally cutting off radiologists. We will lose influence over standards of care. So we must adopt and govern early, or lose the fight later.</p>

    <h2 id="playbook">Practical Suggestions for Applicants and Radiologists, including residents (2025–2030)</h2>
    <p>If you're applying to residency right now or you're a first-year resident wondering what to focus on, here's what to actually do.</p>
    
    <div class="table-wrap">
      <table>
        <thead>
          <tr><th>Step</th><th>What to Do</th><th>Why It Matters</th></tr>
        </thead>
        <tbody>
          <tr>
            <td>Program choice</td>
            <td>Pick residencies with real RIS-PACS analytics and active AI pilots</td>
            <td>You need to learn integration and governance, not just image interpretation. Programs that are actually deploying AI will teach you how to validate tools, monitor for errors and navigate regulatory compliance.<sup>1,3</sup></td>
          </tr>
          <tr>
            <td>Validation literacy</td>
            <td>Volunteer to help with your department's AI validation projects.</td>
            <td>Knowing how to spot when a model is quietly degrading makes you better than 99% of your peers and highly valuable<sup>8</sup></td>
          </tr>
          <tr>
            <td>IR and prevention</td>
            <td>Seek out interventional radiology rotations and preventive imaging pathways (screening programs, follow-up clinics).</td>
            <td>These are high-moat, human-led workflows with growing demand. They're also hard to automate and highly valued by health systems.<sup>15,16</sup></td>
          </tr>
          <tr>
            <td>Regulatory fluency</td>
            <td>Track the EU AI Act, FDA PCCP updates, and in India, the DPDP Act, ABDM health data exchange, and CDSCO medical device rules.</td>
            <td>These frameworks determine what you're allowed to sign, what requires audit trails, and how reimbursement works. Understanding the rules gives you negotiating power.<sup>1,3,9,11</sup></td>
          </tr>
          
        </tbody>
      </table>
    </div>

    <h2 id="advice">My Two Cents, As Directly As I Can Say It</h2>
    <p>I'm going to be direct here, because I think you deserve clarity over comfort.</p>
    
    <p><strong>Yes, AI will surpass the average radiologist at drafting many types of reports some time in the future.</strong> It's already better than humans at detecting certain patterns in controlled test sets. Your edge isn't being faster or more accurate at pattern matching but in knowing <em>when the AI is wrong</em>, and being able to prove it with clinical reasoning and follow-up data.<sup>12</sup> That's judgment, and judgment is still ours.</p>
    
    <p><strong>Expect gradual dependence, and prepare for it.</strong> You'll use AI the way you use a calculator; essential, embedded, hard to work without. The key is treating it like an instrument you master with checklists and quality checks, not a magic box you trust blindly.<sup>8</sup> Maintain your baseline skills. Train without AI periodically. Know what you're capable of when the system goes down. There was an unfortunate AWS outage yesterday in USA and damn, it paralysed everything.</p>
    
    <p><strong>Pivot early to high-moat zones.</strong> Interventional radiology, complex oncologic imaging, preventive programs, clinic leadership roles, and AI safety and governance work: these are the areas where humans add irreplaceable value.<sup>15,16</sup> If you wait until algorithms eat into your bread-and-butter work, you'll be pivoting from a position of weakness. Do it now while you have leverage. One of the major role our lab plays is to provide this leverage to medical students and residents who want to get into AI early.</p>
    
    <p><strong>Get involved in policy, even if you hate bureaucracy.</strong> In India, that means understanding DPDP consent frameworks, the Ayushman Bharat Digital Mission (ABDM) health data exchange standards, and CDSCO medical device approval pathways.<sup>9,10,11</sup> In Europe and the U.S., it's the AI Act and FDA PCCP.<sup>1,3</sup> These regulations decide what you're allowed to sign, what requires a paper trail, and how reimbursement flows. They're written by lawyers and policymakers, but they shape your clinical practice more than any research paper. Radiologists who understand these frameworks will have outsized influence over how AI gets deployed. Those who don't will have it imposed on them.</p>

    <blockquote><strong>Final word:</strong> AI will at some point outperform us on most pattern recognition tasks. That's already happening. But it won't take legal responsibility when things go wrong. The radiologists who thrive in the next decade will be those who <em>use</em> AI as a tool and who know how to <strong>govern</strong> it responsibly. If that sounds interesting to you, radiology is still a great choice. If it sounds like too much work, maybe pick something else. But don't avoid radiology because you're scared of AI. That's the wrong reason.</blockquote>

    <hr>

    <section id="cta">
      <h2>Join Us to shape India's Healthcare AI Story</h2>
      <p>If you're a resident or medical student who wants hands-on experience with responsible AI in real clinical workflows, feel free to reach out to me at suvrankar.datta@ashoka.edu.in. We run multi-institutional projects across India and internationally through the CRASH Lab at Ashoka University, and we have spots for motivated trainees who want to shape how healthcare evolves.</p> 
        
      <p>We also have a general cohort for all doctors who want the early access to different AI tools in healthcare before they become public. You can join at https://chat.whatsapp.com/LkTGRafwE7X09DgVeem93P?mode=wwt </p>
      <p>Email me or DM me on LinkedIn or X. I am usually more responsive over mail.</p>
    </section>

  </article>

  <hr>

  <section class="refs" id="references">
    <h2>References</h2>
    <ol>
      <li id="ref1">European Commission. The Artificial Intelligence Act: overview. Brussels; 2024. Available from: <a href="https://digital-strategy.ec.europa.eu/en/policies/european-ai-act" target="_blank" rel="noopener">https://digital-strategy.ec.europa.eu/en/policies/european-ai-act</a></li>
      
      <li id="ref2">Artificial Intelligence Act (consolidated text). 2024. Available from: <a href="https://artificialintelligenceact.eu/" target="_blank" rel="noopener">https://artificialintelligenceact.eu/</a></li>
      
      <li id="ref3">U.S. Food and Drug Administration. AI/ML-Enabled Medical Devices list. 2025 Jul 10 (updated). Available from: <a href="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device" target="_blank" rel="noopener">FDA SaMD AI/ML</a></li>
      
      <li id="ref4">Zanardo M, et al. Impact of AI on radiology: a EuroAIM/EuSoMII 2024 survey among ESR members. <em>Insights Imaging</em>. 2024. Available from: <a href="https://insightsimaging.springeropen.com/" target="_blank" rel="noopener">Insights Imaging</a></li>
      
      <li id="ref5">Royal College of Radiologists. Clinical Radiology Workforce Census 2024. London: RCR; 2025. Available from: <a href="https://www.rcr.ac.uk" target="_blank" rel="noopener">https://www.rcr.ac.uk</a></li>
      
      <li id="ref6">Boseley S. NHS gave private firms record £216m to examine X-rays in 2024. <em>The Guardian</em>. 2025 May 15. Available from: <a href="https://www.theguardian.com" target="_blank" rel="noopener">https://www.theguardian.com</a></li>
      
      <li id="ref7">Rozenshtein A, et al. The U.S. Radiologist Workforce: AJR Expert Panel Narrative Review. <em>AJR Am J Roentgenol</em>. 2025. Available from: <a href="https://www.ajronline.org" target="_blank" rel="noopener">https://www.ajronline.org</a></li>
      
      <li id="ref8">World Health Organization. Ethics and governance of AI for health: guidance on large multimodal models. Geneva: WHO; 2025. Available from: <a href="https://www.who.int/publications" target="_blank" rel="noopener">https://www.who.int/publications</a></li>
      
      <li id="ref9">Government of India (MeitY). Digital Personal Data Protection Act, 2023. New Delhi; 2023. Available from: <a href="https://www.meity.gov.in/" target="_blank" rel="noopener">https://www.meity.gov.in/</a></li>
      
      <li id="ref10">Press Information Bureau (GoI). ABDM consent-based health-data exchange & cybersecurity updates (2024–2025 releases). Available from: <a href="https://pib.gov.in" target="_blank" rel="noopener">https://pib.gov.in</a></li>
      
      <li id="ref11">Central Drugs Standard Control Organization. Medical Devices Rules 2017 (incl. software as medical device). New Delhi; ongoing. Available from: <a href="https://cdsco.gov.in" target="_blank" rel="noopener">https://cdsco.gov.in</a></li>
      
      <li id="ref12">Dratsch T, et al. Automation bias in mammography: the impact of artificial intelligence BI-RADS suggestions on reader performance. <em>Radiology</em>. 2023;307(4):e222176. Available from: <a href="https://pubs.rsna.org/journal/radiology" target="_blank" rel="noopener">https://pubs.rsna.org/journal/radiology</a></li>
      
      <li id="ref13">Kim SH, et al. Automation bias in AI-assisted detection of cerebral aneurysms. <em>Sci Rep</em>. 2025;15:1234. Available from: <a href="https://www.nature.com/srep/" target="_blank" rel="noopener">https://www.nature.com/srep/</a></li>
      
      <li id="ref14">Abdelwanis M, et al. Automation bias and errors in clinical decision support systems: a systematic review. <em>Patterns</em>. 2024;5(3):100925. Available from: <a href="https://www.cell.com/patterns/" target="_blank" rel="noopener">https://www.cell.com/patterns/</a></li>
      
      <li id="ref15">Lastrucci A, et al. Artificial intelligence and interventional radiology: a narrative review of current applications and future perspectives. <em>EClinicalMedicine</em>. 2025;68:102456. Available from: <a href="https://www.thelancet.com/eclinicalmedicine" target="_blank" rel="noopener">https://www.thelancet.com/eclinicalmedicine</a></li>
      
      <li id="ref16">Lesaunier A, et al. Artificial intelligence in interventional radiology: state of the art. <em>Diagn Interv Imaging</em>. 2025;106(1):12-24. Available from: <a href="https://www.sciencedirect.com/journal/diagnostic-and-interventional-imaging" target="_blank" rel="noopener">https://www.sciencedirect.com/journal/diagnostic-and-interventional-imaging</a></li>
      
      <li id="ref17">Smoła P, et al. Attitudes toward artificial intelligence and robots in medicine among patients. <em>Healthcare (Basel)</em>. 2025;13(2):189. Available from: <a href="https://www.mdpi.com/journal/healthcare" target="_blank" rel="noopener">https://www.mdpi.com/journal/healthcare</a></li>
      
      <li id="ref18">Kühne S, et al. Attitudes toward artificial intelligence usage in patient health care: a cross-sectional survey study. <em>JMIR Human Factors</em>. 2025;12:e52874. Available from: <a href="https://humanfactors.jmir.org/" target="_blank" rel="noopener">https://humanfactors.jmir.org/</a></li>
      
      <li id="ref19">Quantum Metric / TechRadar Pro. UK consumer dissatisfaction with AI chatbots in customer service (2025 report). Available from: <a href="https://www.techradar.com" target="_blank" rel="noopener">https://www.techradar.com</a></li>
      
      <li id="ref20">Davis N. AI could complicate medical liability cases, law experts warn. <em>The Guardian</em>. 2025 Oct 3. Available from: <a href="https://www.theguardian.com" target="_blank" rel="noopener">https://www.theguardian.com</a></li>
    </ol>
  </section>

  <footer>
    <p class="small">© 2025 Dr. Suvrankar Datta • Published October 21, 2025 • Centre for Responsible Autonomous Systems in Healthcare (CRASH Lab), Koita Centre for Digital Health, Ashoka University</p>
  </footer>
</main>
</body>
</html>
