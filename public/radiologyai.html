<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Should You Choose a Radiology Residency in 2025? A Real Talk Guide</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Honest, evidence-based guidance for medical students choosing radiology in the AI era—what will change, what won't, and how to build a future-proof career.">
  
  <link rel="stylesheet" href="index.css">

  <style>
    :root{
      --bg:#ffffff; --text:#111827; --muted:#4b5563; --accent:#0ea5e9; --border:#e5e7eb;
      --code:#0f172a; --kbd:#11182710; --table:#f9fafb;
    }
    html,body{margin:0;padding:0;background:var(--bg);color:var(--text);font:18px/1.7 system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,"Apple Color Emoji","Segoe UI Emoji";}
    main{max-width:820px;margin:auto;padding:50px 24px;}
    header h1{font-size:2.2rem;line-height:1.2;margin:0 0 12px;font-weight:700;}
    header p.byline{color:var(--muted);margin:0 0 32px;font-size:1.05rem;line-height:1.6;}
    article h2{margin-top:48px;font-size:1.6rem;line-height:1.3;font-weight:600;}
    article h3{margin-top:32px;font-size:1.25rem;font-weight:600;}
    article p{margin:16px 0;}
    a{color:var(--accent);text-decoration:none;}
    a:hover{text-decoration:underline;}
    blockquote{margin:24px 0;padding:16px 20px;border-left:4px solid var(--accent);background:#f0f9ff;font-style:italic;}
    .callout{background:#f8fafc;border:1px solid var(--border);padding:20px 24px;border-radius:12px;margin:24px 0;}
    .table-wrap{overflow-x:auto;border:1px solid var(--border);border-radius:12px;margin:20px 0;}
    table{width:100%;border-collapse:collapse;background:var(--table);}
    th,td{padding:12px 16px;border-bottom:1px solid var(--border);text-align:left;vertical-align:top;}
    th{font-weight:600;background:#f9fafb;}
    code,kbd{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;}
    kbd{background:var(--kbd);padding:2px 6px;border-radius:6px;}
    hr{border:none;border-top:1px solid var(--border);margin:40px 0;}
    .refs{margin-top:48px;padding-top:24px;border-top:2px solid var(--border);}
    .refs h2{margin-top:0;}
    .refs ol{padding-left:24px;line-height:1.8;}
    .refs li{margin-bottom:16px;}
    .small{font-size:.95rem;color:var(--muted);}
    sup{font-size:.75em;font-weight:600;}
    footer{margin-top:48px;padding-top:20px;border-top:1px solid var(--border);color:var(--muted);}
    em{font-style:italic;}
    strong{font-weight:600;}
  </style>
</head>
<body>
<main>
  <header>
    <h1>Should You Choose a Radiology Residency in 2025? A Real Talk Guide</h1>
    <p class="byline">By Dr. Suvrankar Datta—radiologist, AI researcher, and someone who thought AI would end his career before it began. I trained at AIIMS New Delhi and now lead the Centre for Responsible Autonomous Systems in Healthcare (CRASH Lab) at Ashoka University's Koita Centre for Digital Health. If you're deciding on radiology right now, here's what I wish someone had told me eight years ago.</p>
  </header>

  <article>
    <h2 id="intro">Let's address the elephant in the room</h2>
    <p>If you're reading this, you're probably lying awake wondering if radiology is a safe bet anymore. I get it. I was you in 2017, except I was convinced AI would eat my career before I finished residency. I read the breathless headlines about deep learning crushing board-certified radiologists on test datasets. I watched Geoffrey Hinton tell a room full of people to stop training radiologists because neural networks would do it better and cheaper.</p>
    
    <p>Eight years later, I'm still here. So is every radiologist I trained with. And honestly, we're busier than ever.</p>
    
    <p>But here's the thing—both the doomers screaming "radiology is dead!" and the optimists saying "AI will never replace doctors!" are wrong. The reality is messier, more interesting, and way more dependent on <em>law and policy</em> than anyone on Twitter wants to admit. After spending nearly a decade building AI systems, validating them in real hospitals, and watching most of them fail to deploy, I've learned that technology is only half the story. The other half is regulation, liability, workforce shortages, and human factors that no algorithm can solve.</p>
    
    <p>This piece is my attempt to cut through the noise and give you the evidence-based picture. Not hype, not fear—just what I believe you need to know as you decide your career in 2025 and beyond.</p>

    <div class="callout">
      <strong>The Bottom Line Up Front</strong>
      <p>Here's the reality in one paragraph: AI keeps getting better at narrow pattern-recognition tasks, and yes, it will keep improving fast. But replacing doctors isn't blocked by <em>accuracy</em> anymore—it's blocked by <em>law and liability</em>. Regulation is tightening everywhere. The EU AI Act classifies most clinical AI as high-risk, requiring explicit human oversight.<sup>1,2</sup> The FDA's approval list is long but every device assumes a human in the loop.<sup>3</sup> In India, the Digital Personal Data Protection Act and medical device rules mean every AI-assisted report needs clear consent trails and audit logs.<sup>9,11</sup> And here's the kicker: because radiologists are scarce—the UK just spent £216 million outsourcing reads in a single year<sup>6</sup>—policy bends toward safe <em>augmentation</em>, not autonomy. A flood of mediocre models is coming, which means stricter post-market monitoring and recalls as real-world errors surface. You'll become dependent on these tools, but with discipline and oversight. Your career strategy? Lean into interventional radiology, preventive imaging programs, clinic leadership, and AI governance literacy. Those are your moats.</p>
    </div>

    <h2 id="what-ai-does">What AI Actually Does (vs. What Twitter Claims)</h2>
    <p>Let's start with what works <em>today</em>, not in some speculative future. AI tools in radiology right now help with triage (flagging urgent cases), quality control (catching technical errors), measurements (tumor volumes, bone density), and report drafting. A big cross-European survey of radiologists—done by EuroAIM and EuSoMII in 2024—found these are the functions doctors actually trust and use in daily practice.<sup>4</sup> Notice the pattern? All of these assume <em>you're</em> still reading the scan and signing the report.</p>
    
    <p>So why isn't this "replacement"? Three reasons, and they're all about systems, not just technology.</p>
    
    <p><strong>First, regulatory scope.</strong> The FDA has cleared over 900 AI devices for medical use,<sup>3</sup> and yes, that number sounds scary. But if you actually read the approval letters, they're for <em>narrow, specific intended uses</em> with explicit disclaimers that a qualified physician must review the output. These aren't autonomous diagnostic systems—they're assistants that generate suggestions, and you're liable for what gets reported. The legal framework treats them more like a second opinion tool than a replacement radiologist.</p>
    
    <p><strong>Second, risk classification.</strong> Under the EU AI Act—which came into force in 2024 and is already influencing global standards—most clinical AI falls into the "high-risk" category.<sup>1,2</sup> That means mandatory risk management systems, high-quality training data with known biases documented, transparent user information, and most critically, <em>explicit human oversight</em> baked into the design. AI governance work is becoming clinical work. If you're annoyed by paperwork now, wait until you're the designated model steward for your department.</p>
    
    <p><strong>Third, human factors.</strong> Even when AI is accurate, humans mess up the interaction. The literature is full of studies showing <em>automation bias</em>—experienced readers getting nudged by wrong AI suggestions and missing things they'd normally catch.<sup>12,13,14</sup> Radiologists in one mammography study were more likely to overlook subtle cancers when an AI wrongly flagged a different area as suspicious.<sup>12</sup> Another study on cerebral aneurysm detection found that wrong AI suggestions actively degraded reader performance.<sup>13</sup> This isn't theoretical—it's happening in pilot studies right now. The answer isn't to throw AI out, but to design guardrails: deliberate training, cross-checks, and incident reporting systems that actually work.</p>

    <h2 id="shortage">Why Governments Move Slower Than Tech Bros Think</h2>
    <p>Here's something Silicon Valley doesn't want to hear: laws change when <em>shortages</em> bite, not when algorithms get better. And the evidence backs this up everywhere you look.</p>
    
    <p>The Royal College of Radiologists released their 2024 UK workforce census, and the picture is stark—demand for imaging is outpacing radiologist supply by a wide margin.<sup>5</sup> The NHS is stretched so thin that in 2024 alone, they spent a record £216 million outsourcing radiology reads to private firms and teleradiology companies.<sup>6</sup> That's not a one-time blip—it's a structural problem. Backlogs are measured in months for non-urgent scans. Politicians know this. Hospital administrators know this. And guess what? It shapes <em>policy</em> more than any AI benchmark.</p>
    
    <p>When governments face scarcity, they don't jump straight to "replace doctors with algorithms." They bend toward safe augmentation—tools that help existing radiologists work faster and catch more, but still require a licensed professional to sign off. Why? Because when something goes wrong, someone needs to be legally accountable, and right now, algorithms can't be sued.<sup>20</sup></p>
    
    <p>In India, AI deployment is shaped by two big frameworks. First, the Digital Personal Data Protection Act (DPDP) of 2023, which gives patients consent rights over how their health data is used—including by AI systems.<sup>9</sup> Second, the Central Drugs Standard Control Organization (CDSCO) classifies AI software as a medical device under the Medical Devices Rules 2017, which means it needs approval, post-market surveillance, and traceable use.<sup>11</sup> The practical result? You won't see "AI-only" reports in Indian hospitals anytime soon. There will always be a radiologist's name and signature on that report, with audit trails showing how the AI contributed.</p>

    <h2 id="flood">The Coming Wave of Mediocre Models (and How They'll Be Regulated)</h2>
    <p>Here's an uncomfortable truth: model-making has been democratized, but deployment hasn't. Anyone with a GPU and a weekend can train a model on ImageNet or ChestX-ray14 and claim it "detects pneumonia." There are startups launching AI radiology tools every single week. Most of them will be mediocre.</p>
    
    <p>Why? Because these models fall apart when they see data from a different scanner, a different patient population, or even a different hospital's imaging protocols. Machine learning researchers call this "out-of-distribution" failure, and it's a massive problem that most companies don't advertise until after they've signed contracts.</p>
    
    <p>Regulators know this, which is why frameworks are getting stricter, not looser. The FDA's Predetermined Change Control Plan (PCCP) allows AI companies to update their models—but only within a pre-approved envelope of changes, and they have to prove the updates don't break safety or effectiveness.<sup>3</sup> The World Health Organization's guidance on large multimodal models is even more explicit: it calls for <em>local validation</em> on your specific patient population and equipment before you trust any model with clinical decisions, plus ongoing monitoring for drift.<sup>8</sup> If a model starts quietly degrading because your patient mix changed or your CT scanner got a software update, you need to catch it.</p>
    
    <p>Translation for you as a resident: expect more work, not less. Someone in your department will need to be the AI steward—tracking performance metrics, running quarterly validation checks, documenting when the AI influenced a decision, and knowing when to pull the plug if things go wrong. That someone might be you.</p>

    <h2 id="dependence">You'll Become Dependent on AI (and That's Okay, If You're Smart About It)</h2>
    <p>Let's be honest—calculator-style reliance is inevitable. Once you get used to AI triaging your worklist and pre-measuring nodules, working without it feels like going back to film. The literature already flags this as <em>automation complacency</em> and hints at de-skilling when assistive tools are suddenly withdrawn.<sup>12,13,14</sup> Residents trained with AI available struggle more when they don't have access to it, similar to how GPS dependence has changed how we navigate.</p>
    
    <p>The answer isn't abstinence—it's <em>structured supervision</em> and education. You need to train with AI, but also train <em>without</em> it periodically, so you maintain your baseline skills. Think of it like a pilot practicing manual landings even though autopilot exists. You want to be the person who knows when the AI is wrong, not the person who blindly trusts it.</p>
    
    <p>And here's something else to consider: patients are ambivalent about this stuff. Surveys show mixed trust in AI for medical care, with a strong preference for human doctors in emotionally loaded situations—breaking bad news, discussing end-of-life care, or explaining complex diagnoses.<sup>17,18</sup> A 2025 UK report found that consumers are increasingly frustrated with low-quality chatbots and automated customer service, and that frustration bleeds into healthcare expectations.<sup>19</sup> If we ship "AI slop"—fast, cheap, inaccurate automation that feels impersonal—there will be backlash. Patients will demand their human radiologist back, and rightly so.</p>
    
    <p><strong>Clinic guardrails that actually work:</strong> Run local validation on your hospital's imaging equipment and patient demographics. Appoint a named model steward who owns the performance monitoring. Document in the radiology report when AI contributed to a finding or changed your interpretation. Monitor for drift—performance decay over time as patient populations or equipment change. Have an incident response plan for when the AI gets something badly wrong. Write plain-language patient notes explaining when AI was used in their care. These align with WHO guidance and EU AI Act expectations,<sup>1,8</sup> and more importantly, they build trust.</p>

    <h2 id="human-touch">Where Humans Still Dominate (and Where Radiology Actually Grows)</h2>
    <p>Let's talk about the safe zones—the parts of medicine where AI isn't close to replacing us, and won't be for a very long time.</p>
    
    <p><strong>Surgical and patient-facing specialties</strong> rely on trust, context, consent, and hands-on skill. AI can assist, but it can't replace the judgment call in the OR when something unexpected happens, or the conversation in clinic when a patient needs to understand their treatment options. Patient experience studies repeatedly show that people prefer talking to actual staff over bots when the stakes are high or the interaction is emotionally charged.<sup>17</sup> This isn't sentimentality—it's psychology and ethics. Medicine is built on relationships, and those relationships still matter.</p>
    
    <p><strong>Interventional Radiology (IR) is your best hedge.</strong> AI helps with targeting lesions, choosing devices, and intra-procedural navigation—there are systems that use real-time imaging fusion and robotics to guide catheters more precisely.<sup>15,16</sup> But the workflow remains human-led. You're adapting on the fly based on what you see, what the patient tolerates, and what the anatomy allows. Recent reviews forecast higher throughput and safety with AI-assisted guidance, but not fully autonomous IR.<sup>15,16</sup> Why? Because liability, patient variability, and the need for real-time judgment aren't going away. If you want a future-proof radiology career, get IR training. It's procedural, it's patient-facing, and it's hard to automate.</p>
    
    <p><strong>Preventive and longitudinal radiology</strong> is another growth area. Screening programs for breast and lung cancer, osteoporosis follow-up, incidental findings management—these all benefit from AI's systematic review and recall management, but they require a radiologist to oversee the pathway and make the call on borderline cases.<sup>4</sup> This is clinical leadership work, not just image interpretation. You're designing the screening protocol, deciding on recall thresholds, managing patient anxiety, and integrating imaging into long-term care plans. AI can help, but it can't own the relationship with the referring physician or the patient.</p>

    <h2 id="economics">Let's Talk Money (Because You're Thinking About It)</h2>
    <p>Nobody wants to say it out loud, but earning potential matters when you're choosing a specialty. So let's address it directly.</p>
    
    <p><strong>If you end up in an independent or teleradiology practice,</strong> AI can improve your margins—but only if you reinvest the efficiency gains into quality and retention. Faster turnaround times, fewer repeat scans, better structured reports—all of this builds referrer loyalty. But if you just pocket the savings and don't reinvest in your radiologists, you'll bleed talent. The UK's cautionary tale is instructive: they starved their radiology workforce for years, and now they're hemorrhaging money on outsourcing.<sup>6</sup> Don't let that happen to your practice.</p>
    
    <p><strong>If you're an employed radiologist,</strong> the invisible work matters. AI doesn't just speed you up—it adds new tasks. Local validation, exception handling, patient callbacks when AI flags something ambiguous, teaching residents how to use the tools safely—all of this takes time, and most contracts don't account for it. The American Journal of Roentgenology's Expert Panel on workforce issues explicitly calls for new staffing and reimbursement models that recognize these safety tasks.<sup>7</sup> When you're negotiating your contract, make sure AI stewardship is part of your job description, not free labor.</p>
    
    <p>The other economic reality: if radiologists refuse to adopt safe, auditable AI tools, <em>referring clinicians will</em>. Emergency physicians, oncologists, and surgeons are already experimenting with point-of-care ultrasound AI and direct-to-consumer imaging apps. If we don't set the standards for how AI is used in imaging, someone else will—and they'll optimize for speed and cost, not quality and safety. We lose influence over standards of care. Adopt and govern early, or lose the fight later.</p>

    <h2 id="playbook">Practical Playbook for Applicants and Residents (2025–2030)</h2>
    <p>Okay, enough theory. If you're applying to residency right now or you're a first-year resident wondering what to focus on, here's what to actually do.</p>
    
    <div class="table-wrap">
      <table>
        <thead>
          <tr><th>Step</th><th>What to Do</th><th>Why It Matters</th></tr>
        </thead>
        <tbody>
          <tr>
            <td>Program choice</td>
            <td>Pick residencies with real RIS-PACS analytics and active AI pilots—not just vendor demos or press releases.</td>
            <td>You need to learn integration and governance, not just image interpretation. Programs that are actually deploying AI will teach you how to validate tools, monitor for errors, and navigate regulatory compliance.<sup>1,3</sup></td>
          </tr>
          <tr>
            <td>Validation literacy</td>
            <td>Learn to run subgroup analysis and calibration checks on a local test set. Volunteer to help with your department's AI validation projects.</td>
            <td>This prevents silent drift and builds safety credibility. Knowing how to spot when a model is quietly degrading makes you indispensable.<sup>8</sup></td>
          </tr>
          <tr>
            <td>IR and prevention</td>
            <td>Seek out interventional radiology rotations and preventive imaging pathways (screening programs, follow-up clinics).</td>
            <td>These are high-moat, human-led workflows with growing demand. They're also hard to automate and highly valued by health systems.<sup>15,16</sup></td>
          </tr>
          <tr>
            <td>Regulatory fluency</td>
            <td>Track the EU AI Act, FDA PCCP updates, and in India, the DPDP Act, ABDM health data exchange, and CDSCO medical device rules.</td>
            <td>These frameworks determine what you're allowed to sign, what requires audit trails, and how reimbursement works. Understanding the rules gives you negotiating power.<sup>1,3,9,11</sup></td>
          </tr>
          <tr>
            <td>Communication skills</td>
            <td>Practice writing plain-language explanations of AI use for patients. Add a sentence to your reports when AI contributed meaningfully to a finding.</td>
            <td>Transparency builds trust and aligns with global guidance. Patients appreciate knowing how their care was delivered, and it protects you legally.<sup>8</sup></td>
          </tr>
        </tbody>
      </table>
    </div>

    <h2 id="advice">My Advice, As Plainly As I Can Say It</h2>
    <p>I'm going to be direct here, because I think you deserve clarity over comfort.</p>
    
    <p><strong>Yes, AI will surpass the average radiologist at drafting many types of reports.</strong> It's already better than humans at detecting certain patterns in controlled test sets. Your edge isn't being faster or more accurate at pattern matching—your edge is knowing <em>when the AI is wrong</em>, and being able to prove it with clinical reasoning and follow-up data.<sup>12</sup> That's judgment, and judgment is still ours.</p>
    
    <p><strong>Expect gradual dependence, and prepare for it.</strong> You'll use AI the way you use a calculator—essential, embedded, hard to work without. The key is treating it like an instrument you master with checklists and quality checks, not a magic box you trust blindly.<sup>8</sup> Maintain your baseline skills. Train without AI periodically. Know what you're capable of when the system goes down.</p>
    
    <p><strong>Pivot early to high-moat zones.</strong> Interventional radiology, complex oncologic imaging, preventive programs, clinic leadership roles, and AI safety and governance work—these are the areas where humans add irreplaceable value.<sup>15,16</sup> If you wait until algorithms eat into your bread-and-butter work, you'll be pivoting from a position of weakness. Do it now while you have leverage.</p>
    
    <p><strong>Get involved in policy, even if you hate bureaucracy.</strong> In India, that means understanding DPDP consent frameworks, the Ayushman Bharat Digital Mission (ABDM) health data exchange standards, and CDSCO medical device approval pathways.<sup>9,10,11</sup> In Europe and the U.S., it's the AI Act and FDA PCCP.<sup>1,3</sup> These regulations decide what you're allowed to sign, what requires a paper trail, and how reimbursement flows. They're written by lawyers and policymakers, but they shape your clinical practice more than any research paper. Radiologists who understand these frameworks will have outsized influence over how AI gets deployed. Those who don't will have it imposed on them.</p>

    <blockquote><strong>Final word:</strong> AI will out-analyze us on narrow pattern recognition tasks. That's already happening. But it won't out-care for patients, won't navigate the messy grey zones of clinical judgment, and won't take legal responsibility when things go wrong. The radiologists who thrive in the next decade will be those who <em>use</em> AI as a tool—and who know how to <strong>govern</strong> it responsibly. If that sounds interesting to you, radiology is still a great choice. If it sounds like too much work, maybe pick something else. But don't avoid radiology because you're scared of algorithms. That's the wrong reason.</blockquote>

    <hr>

    <section id="cta">
      <h2>Work With Us</h2>
      <p>If you're a resident or medical student who wants hands-on experience with <em>safe</em>, <em>auditable</em> AI in real clinical workflows—validation, monitoring, governance, the works—reach out to me. We run multi-institutional projects across India and internationally through the CRASH Lab at Ashoka University, and we have spots for motivated trainees who want to shape how radiology evolves instead of just reacting to it.</p>
      <p>Email me at the KCDH contact page if this sounds like you. Come build the future with us.</p>
    </section>

  </article>

  <hr>

  <section class="refs" id="references">
    <h2>References</h2>
    <ol>
      <li id="ref1">European Commission. The Artificial Intelligence Act: overview. Brussels; 2024. Available from: <a href="https://digital-strategy.ec.europa.eu/en/policies/european-ai-act" target="_blank" rel="noopener">https://digital-strategy.ec.europa.eu/en/policies/european-ai-act</a></li>
      
      <li id="ref2">Artificial Intelligence Act (consolidated text). 2024. Available from: <a href="https://artificialintelligenceact.eu/" target="_blank" rel="noopener">https://artificialintelligenceact.eu/</a></li>
      
      <li id="ref3">U.S. Food and Drug Administration. AI/ML-Enabled Medical Devices list. 2025 Jul 10 (updated). Available from: <a href="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device" target="_blank" rel="noopener">FDA SaMD AI/ML</a></li>
      
      <li id="ref4">Zanardo M, et al. Impact of AI on radiology: a EuroAIM/EuSoMII 2024 survey among ESR members. <em>Insights Imaging</em>. 2024. Available from: <a href="https://insightsimaging.springeropen.com/" target="_blank" rel="noopener">Insights Imaging</a></li>
      
      <li id="ref5">Royal College of Radiologists. Clinical Radiology Workforce Census 2024. London: RCR; 2025. Available from: <a href="https://www.rcr.ac.uk" target="_blank" rel="noopener">https://www.rcr.ac.uk</a></li>
      
      <li id="ref6">Boseley S. NHS gave private firms record £216m to examine X-rays in 2024. <em>The Guardian</em>. 2025 May 15. Available from: <a href="https://www.theguardian.com" target="_blank" rel="noopener">https://www.theguardian.com</a></li>
      
      <li id="ref7">Rozenshtein A, et al. The U.S. Radiologist Workforce: AJR Expert Panel Narrative Review. <em>AJR Am J Roentgenol</em>. 2025. Available from: <a href="https://www.ajronline.org" target="_blank" rel="noopener">https://www.ajronline.org</a></li>
      
      <li id="ref8">World Health Organization. Ethics and governance of AI for health: guidance on large multimodal models. Geneva: WHO; 2025. Available from: <a href="https://www.who.int/publications" target="_blank" rel="noopener">https://www.who.int/publications</a></li>
      
      <li id="ref9">Government of India (MeitY). Digital Personal Data Protection Act, 2023. New Delhi; 2023. Available from: <a href="https://www.meity.gov.in/" target="_blank" rel="noopener">https://www.meity.gov.in/</a></li>
      
      <li id="ref10">Press Information Bureau (GoI). ABDM consent-based health-data exchange & cybersecurity updates (2024–2025 releases). Available from: <a href="https://pib.gov.in" target="_blank" rel="noopener">https://pib.gov.in</a></li>
      
      <li id="ref11">Central Drugs Standard Control Organization. Medical Devices Rules 2017 (incl. software as medical device). New Delhi; ongoing. Available from: <a href="https://cdsco.gov.in" target="_blank" rel="noopener">https://cdsco.gov.in</a></li>
      
      <li id="ref12">Dratsch T, et al. Automation bias in mammography: the impact of artificial intelligence BI-RADS suggestions on reader performance. <em>Radiology</em>. 2023;307(4):e222176. Available from: <a href="https://pubs.rsna.org/journal/radiology" target="_blank" rel="noopener">https://pubs.rsna.org/journal/radiology</a></li>
      
      <li id="ref13">Kim SH, et al. Automation bias in AI-assisted detection of cerebral aneurysms. <em>Sci Rep</em>. 2025;15:1234. Available from: <a href="https://www.nature.com/srep/" target="_blank" rel="noopener">https://www.nature.com/srep/</a></li>
      
      <li id="ref14">Abdelwanis M, et al. Automation bias and errors in clinical decision support systems: a systematic review. <em>Patterns</em>. 2024;5(3):100925. Available from: <a href="https://www.cell.com/patterns/" target="_blank" rel="noopener">https://www.cell.com/patterns/</a></li>
      
      <li id="ref15">Lastrucci A, et al. Artificial intelligence and interventional radiology: a narrative review of current applications and future perspectives. <em>EClinicalMedicine</em>. 2025;68:102456. Available from: <a href="https://www.thelancet.com/eclinicalmedicine" target="_blank" rel="noopener">https://www.thelancet.com/eclinicalmedicine</a></li>
      
      <li id="ref16">Lesaunier A, et al. Artificial intelligence in interventional radiology: state of the art. <em>Diagn Interv Imaging</em>. 2025;106(1):12-24. Available from: <a href="https://www.sciencedirect.com/journal/diagnostic-and-interventional-imaging" target="_blank" rel="noopener">https://www.sciencedirect.com/journal/diagnostic-and-interventional-imaging</a></li>
      
      <li id="ref17">Smoła P, et al. Attitudes toward artificial intelligence and robots in medicine among patients. <em>Healthcare (Basel)</em>. 2025;13(2):189. Available from: <a href="https://www.mdpi.com/journal/healthcare" target="_blank" rel="noopener">https://www.mdpi.com/journal/healthcare</a></li>
      
      <li id="ref18">Kühne S, et al. Attitudes toward artificial intelligence usage in patient health care: a cross-sectional survey study. <em>JMIR Human Factors</em>. 2025;12:e52874. Available from: <a href="https://humanfactors.jmir.org/" target="_blank" rel="noopener">https://humanfactors.jmir.org/</a></li>
      
      <li id="ref19">Quantum Metric / TechRadar Pro. UK consumer dissatisfaction with AI chatbots in customer service (2025 report). Available from: <a href="https://www.techradar.com" target="_blank" rel="noopener">https://www.techradar.com</a></li>
      
      <li id="ref20">Davis N. AI could complicate medical liability cases, law experts warn. <em>The Guardian</em>. 2025 Oct 3. Available from: <a href="https://www.theguardian.com" target="_blank" rel="noopener">https://www.theguardian.com</a></li>
    </ol>
  </section>

  <footer>
    <p class="small">© 2025 Dr. Suvrankar Datta • Published October 20, 2025 • Centre for Responsible Autonomous Systems in Healthcare (CRASH Lab), Koita Centre for Digital Health, Ashoka University</p>
  </footer>
</main>
</body>
</html>
